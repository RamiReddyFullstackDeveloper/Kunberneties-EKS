#!/bin/bash

#Official website
https://docs.aws.amazon.com/eks/latest/userguide/what-is-eks.html

#Refer the below git repo for setup with amazon eks
https://github.com/vikas99341/k8s-masterclass/blob/main/EKS/eksctl

#Prerequisites
1> AWSCLI 
2> Kubectl
3> Eksctl --> eksctl version
4> Create an IAM role and attach to EC2 machine
   (Administrative, IAMFullAccess, CloudFormation, )

Kubernates
------------------------------------------------
#What is Kubernates?
Kubernates is also know as K8s, and it is open source container orchestration system for automatic software deployment, scaling and management of containerized applications.

#What is the kubectl?
Kubernetes provides a command line tool for communicating with a Kubernetes cluster's control plane, using the Kubernetes API. This tool is named kubectl.'
For configuration, kubectl looks for a file named config in the $HOME/.kube directory.
Using Kubectl allows you to create, inspect, update, and delete Kubernetes objects

#What is the eksctl?
eksctl is also command line interface tool for creating and managing clusters on EKS.


#What is the KOPS ? https://kops.sigs.k8s.io/getting_started/aws/
KOPS: Kubernates operations, kops is easiest way to get a production grade Kubernetes cluster up and running.
kops will not only help you create, destroy, upgrade and maintain production-grade, highly available, Kubernetes cluster, but it will also provision the necessary cloud infrastructure.
#KOPS Features¶
Automates the provisioning of Highly Available Kubernetes clusters
Built on a state-sync model for dry-runs and automatic idempotency
Ability to generate Terraform
Supports zero-config managed kubernetes add-ons
Command line autocompletion
YAML Manifest Based API Configuration
Templating and dry-run modes for creating Manifests
Choose from most popular CNI Networking providers out-of-the-box
Multi-architecture ready with ARM64 support
Capability to add containers, as hooks, and files to nodes via a cluster manifest


#kubernates setup in EKS
==============================================================================
https://github.com/vikas99341/k8s-masterclass/blob/main/EKS/eksctl
#Before starting this tutorial, you must install and configure the following tools and resources that you need to create and manage an Amazon EKS cluster.
kubectl and eksctl both must be required.
#kubectl : Refer official website https://docs.aws.amazon.com/eks/latest/userguide/install-kubectl.html
=================================
#Determine whether you already have kubectl installed on your device.
$ kubectl version --short --client
#Install or update kubectl on Linux operating systems.   
$ curl -O https://s3.us-west-2.amazonaws.com/amazon-eks/1.27.1/2023-04-19/bin/linux/amd64/kubectl
#Apply execute permissions to the binary.
$ chmod +x ./kubectl
#Copy the binary to a folder in your PATH. If you have already installed a version of kubectl, then we recommend creating a $HOME/bin/kubectl and ensuring that $HOME/bin comes first in your $PATH
$ mkdir -p $HOME/bin && cp ./kubectl $HOME/bin/kubectl && export PATH=$HOME/bin:$PATH
#(Optional) Add the $HOME/bin path to your shell initialization file so that it is configured when you open a shell.
$ echo 'export PATH=$HOME/bin:$PATH' >> ~/.bashrc
#After you install kubectl, you can verify its version.
$ kubectl version --short --client

#eksctl : Refer official website 
================================
https://docs.aws.amazon.com/eks/latest/userguide/eksctl.html
https://github.com/weaveworks/eksctl/blob/main/README.md#installation  # For eksctl installation

#eksctl: is a simple command line tool for creating and managing Kubernetes clusters on Amazon EKS. eksctl provides the fastest and easiest way to create a new cluster with nodes for Amazon EKS. 

#Determine whether you already have eksctl installed on your device.
$ eksctl version
# for ARM systems, set ARCH to: `arm64`, `armv6` or `armv7`
#Approach1
----------
ARCH=amd64
PLATFORM=$(uname -s)_$ARCH

curl -sLO "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$PLATFORM.tar.gz"
# (Optional) Verify checksum
curl -sL "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_checksums.txt" | grep $PLATFORM | sha256sum --check
tar -xzf eksctl_$PLATFORM.tar.gz -C /tmp && rm eksctl_$PLATFORM.tar.gz
sudo mv /tmp/eksctl /usr/local/bin

#Approach2:
---------
   ```sh
   curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
   sudo mv /tmp/eksctl /usr/local/bin
   eksctl version```

#Create IAM roles and attach to EC2 instance on which machine cluster runs
============================================================================
`Note: create IAM user with programmatic access if your bootstrap system is outside of AWS`
Refer https://eksctl.io/usage/minimum-iam-policies/

First create Roles :
IAMFULLAccess
EC2FullAccess 
CloudFormationFullAccess
AmazonEKSClusterPolicy.
AdministratorAccess

and go go to EC2 instance and click on Actions --> Security ---> Modify IAM Role--> chose Role.

#Step1: Create your Amazon EKS cluster and nodes
==========================================
this topic includes steps to create a cluster and nodes with default settings. Before creating a cluster and nodes for production use, we recommend that you familiarize yourself with all settings and deploy a cluster and nodes with the settings that meet your requirements.
#Cluster:
========
https://docs.aws.amazon.com/eks/latest/userguide/create-cluster.html
#Nodes: ple refer this official website https://docs.aws.amazon.com/eks/latest/userguide/eks-compute.html
A Kubernetes node is a machine that runs containerized applications. Each node has the following components:
Container runtime – Software that's responsible for running the containers'
kubelet – Makes sure that containers are healthy and running within their associated Pod.
kube-proxy – Maintains network rules that allow communication to your Pods.

You can create a cluster with one of the following node types. To learn more about each type, see Amazon EKS nodes. After your cluster is deployed, you can add other node types.

#Fargate – Linux –:
Select this type of node if you want to run Linux applications on AWS Fargate. Fargate is a serverless compute engine that lets you deploy Kubernetes Pods without managing Amazon EC2 instances.

#Managed nodes – Linux :
Select this type of node if you want to run Amazon Linux applications on Amazon EC2 instances. Though not covered in this guide, you can also add Windows self-managed and Bottlerocket nodes to your cluster.

Create your Amazon EKS cluster with the following command. You can replace my-cluster with your own value.
$eksctl create cluster --name my-cluster --region region-code --fargate
$eksctl create cluster --name my-cluster --region ap-south-1 --fargate
 Ex:
   $eksctl create cluster --name cluster-name  \
   --region region-name \
   --node-type instance-type \
   --nodes-min 2 \
   --nodes-max 2 \ 
   --zones <AZ-1>,<AZ-2>
   $eksctl create cluster --name demo-cluster --region us-east-1 --node-type t2.medium
   $eksctl create cluster --name demo-cluster --region ap-south-1 --node-type t2.medium
#Output:
[root@k8s-mgmt-svr ~]# eksctl create cluster --name demo-cluster --region ap-south-1 --node-type t2.medium
2023-06-02 13:07:56 [ℹ]  eksctl version 0.143.0
2023-06-02 13:07:56 [ℹ]  using region ap-south-1
2023-06-02 13:07:56 [ℹ]  skipping ap-south-1c from selection because it doesn't support the following instance type(s): t2.medium
2023-06-02 13:07:56 [ℹ]  setting availability zones to [ap-south-1a ap-south-1b]
2023-06-02 13:07:56 [ℹ]  subnets for ap-south-1a - public:192.168.0.0/19 private:192.168.64.0/19
2023-06-02 13:07:56 [ℹ]  subnets for ap-south-1b - public:192.168.32.0/19 private:192.168.96.0/19
2023-06-02 13:07:56 [ℹ]  nodegroup "ng-dc7893ee" will use "" [AmazonLinux2/1.25]
2023-06-02 13:07:56 [ℹ]  using Kubernetes version 1.25
2023-06-02 13:07:56 [ℹ]  creating EKS cluster "demo-cluster" in "ap-south-1" region with managed nodes
2023-06-02 13:07:56 [ℹ]  will create 2 separate CloudFormation stacks for cluster itself and the initial managed nodegroup
2023-06-02 13:07:56 [ℹ]  if you encounter any issues, check CloudFormation console or try 'eksctl utils describe-stacks --region=ap-south-1 --cluster=demo-cluster'
2023-06-02 13:07:56 [ℹ]  Kubernetes API endpoint access will use default of {publicAccess=true, privateAccess=false} for cluster "demo-cluster" in "ap-south-1"
2023-06-02 13:07:56 [ℹ]  CloudWatch logging will not be enabled for cluster "demo-cluster" in "ap-south-1"
2023-06-02 13:07:56 [ℹ]  you can enable it with 'eksctl utils update-cluster-logging --enable-types={SPECIFY-YOUR-LOG-TYPES-HERE (e.g. all)} --region=ap-south-1 --cluster=demo-cluster'
2023-06-02 13:07:56 [ℹ]
2 sequential tasks: { create cluster control plane "demo-cluster",
    2 sequential sub-tasks: {
        wait for control plane to become ready,
        create managed nodegroup "ng-dc7893ee",
    }
}
2023-06-02 13:07:56 [ℹ]  building cluster stack "eksctl-demo-cluster-cluster"
2023-06-02 13:07:57 [ℹ]  deploying stack "eksctl-demo-cluster-cluster"
2023-06-02 13:08:27 [ℹ]  waiting for CloudFormation stack "eksctl-demo-cluster-cluster"
2023-06-02 13:23:06 [ℹ]  waiting for CloudFormation stack "eksctl-demo-cluster-nodegroup-ng-dc7893ee"
2023-06-02 13:23:06 [ℹ]  waiting for the control plane to become ready
2023-06-02 13:23:07 [✔]  saved kubeconfig as "/root/.kube/config"
2023-06-02 13:23:07 [ℹ]  no tasks
2023-06-02 13:23:07 [✔]  all EKS cluster resources for "demo-cluster" have been created
2023-06-02 13:23:07 [ℹ]  nodegroup "ng-dc7893ee" has 2 node(s)
2023-06-02 13:23:07 [ℹ]  node "ip-192-168-29-206.ap-south-1.compute.internal" is ready
2023-06-02 13:23:07 [ℹ]  node "ip-192-168-62-169.ap-south-1.compute.internal" is ready
2023-06-02 13:23:07 [ℹ]  waiting for at least 2 node(s) to become ready in "ng-dc7893ee"
2023-06-02 13:23:07 [ℹ]  nodegroup "ng-dc7893ee" has 2 node(s)
2023-06-02 13:23:07 [ℹ]  node "ip-192-168-29-206.ap-south-1.compute.internal" is ready
2023-06-02 13:23:07 [ℹ]  node "ip-192-168-62-169.ap-south-1.compute.internal" is ready
2023-06-02 13:23:09 [ℹ]  kubectl command should work with "/root/.kube/config", try 'kubectl get nodes'
2023-06-02 13:23:09 [✔]  EKS cluster "demo-cluster" in "ap-south-1" region is ready
[root@k8s-mgmt-svr ~]#'

   
Note: Cluster creation takes several minutes. During creation you will see several lines of output. The last line of output is similar to the following example line.
#Note:
Once you have created a cluster, you will find that cluster credentials were added in ~/.kube/config
$ cat ~/.kube/config 

eksctl created a kubectl config file in ~/.kube or added the new cluster's configuration within an existing config file in ~/.kube on your computer.'

After cluster creation is complete, view the AWS CloudFormation stack named demo-cluster-cluster in the AWS CloudFormation console at https://console.aws.amazon.com/cloudformation to see all of the resources that were created.

#Step 2: View Kubernetes resources
=================================================================
#View your cluster nodes.
$kubectl get nodes -o wide

#For Example output like this
NAME                                                STATUS   ROLES    AGE     VERSION              INTERNAL-IP   EXTERNAL-IP   OS-IMAGE         KERNEL-VERSION                  CONTAINER-RUNTIME
fargate-ip-192-0-2-0.region-code.compute.internal   Ready    <none>   8m3s    v1.2.3-eks-1234567   192.0.2.0     <none>        Amazon Linux 2   1.23.456-789.012.amzn2.x86_64   containerd://1.2.3
fargate-ip-192-0-2-1.region-code.compute.internal   Ready    <none>   7m30s   v1.2.3-eks-1234567   192-0-2-1     <none>        Amazon Linux 2   1.23.456-789.012.amzn2.x86_64   containerd://1.2.3

#View the workloads running on your cluster.
$kubectl get pods -A -o wide
#for example output is as follows
NAMESPACE     NAME                       READY   STATUS    RESTARTS   AGE   IP          NODE                                                NOMINATED NODE   READINESS GATES
kube-system   coredns-1234567890-abcde   1/1     Running   0          18m   192.0.2.0   fargate-ip-192-0-2-0.region-code.compute.internal   <none>           <none>
kube-system   coredns-1234567890-12345   1/1     Running   0          18m   192.0.2.1   fargate-ip-192-0-2-1.region-code.compute.internal   <none>           <none>

#Describe the pods
$kubectl describe pod <name of the pod>
$kubectl describe pod coredns-1234567890-abcde

#To delete the EKS cluster
$ eksctl delete cluster demo-cluster --region ap-south-1

# Deploying Nginx pods on Kubernetes
====================================
#Deploying Nginx Container:
$ kubectl create deployment  demo-nginx --image=nginx --replicas=2 --port=80

$kubectl get deployment
[root@k8s-mgmt-svr ~]# kubectl get deployment
NAME         READY   UP-TO-DATE   AVAILABLE   AGE
demo-nginx   2/2     2            2           22m

$ kubectl get all
[root@k8s-mgmt-svr .kube]# kubectl get all
NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.100.0.1   <none>        443/TCP   45m


#Expose the deployment as service. This will create an ELB in front of those 2 containers and allow us to publicly access them.
$ kubectl expose deployment demo-nginx --port=80 --type=LoadBalancer

$ kubectl get svc demo-nginx # this commands will give you the url to access remotely.
[root@k8s-mgmt-svr ~]# kubectl get svc demo-nginx
NAME         TYPE           CLUSTER-IP       EXTERNAL-IP                                                                PORT(S)        AGE
demo-nginx   LoadBalancer   10.100.143.146   a8f787949ee6f4f0e8cddfcf68db9d2d-1322773865.ap-south-1.elb.amazonaws.com   80:30724/TCP   31m

# go to browser and hit with this url then u will see the nginx default index.html page content
a8f787949ee6f4f0e8cddfcf68db9d2d-1322773865.ap-south-1.elb.amazonaws.com

#What is the kubelet in kubernets?
kubelet is the primary "node agent" that runs on each node. It can register the nore with api server using one of it one of the hostname.
The kubelet works in terms of a PodSpec. A PodSpec is a YAML or JSON object that describes a pod.
	
1> Where were you run the eksctl cluster commmand
2> what is different between kubectl and eksctl
3> Which parameter is should use to scale up and scale down? CPU Utalization by default > 70 %

4> u said u will teach about service for expose service
